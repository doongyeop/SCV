# A107 SCV 포팅메뉴얼

> **BACK**  
> OpenJDK 21  
> Spring Boot 3.3.5  
> Spring Security 6.3.4  
> Spring Data JPA 3.3.5  
> Query DSL 5.0.0  
> mysql 8.0.38  
> redis 7.4.1

> **FRONT**  
> Next.js 15.0.3  
> Tailwind css 3.4.1  
> Typescript 5  
> Tanscatck Query 5.59.15  
> Zustand 5.0.0  
> yarn 4.5.1

> **INFRA**  
> AWS EC2  
> AWS G4.xLarge  
> Kubernetes 1.29.10  
> Docker 27.3.1  
> Jenkins 2.479.1  
> NginX 1.18.0-0  
> Ubuntu 20.04
> CuDNN x86_64 Ubuntu 20.04 5.15.0(Kernel) 9.4.0(GCC) 2.31(Glibc)
> Nvidia GPU Drivers 450 이상 535.183.01
> Nvidia Container Toolkit
> Nvidia Device Plugin
> Nvidia CUDA Toolkit 11.8

> **AI**  
> Python 3.12.4  
> Pytorch 2.5.1  
> MinIO 24-11-07  
> Milvus 2.4.13

> **IDE**  
> IntelliJ IDEA 2024.1.4  
> Visual Studio Code 1.90.2  
> Data Grip 2024.2.2

# 쿠버네티스 설치 (containerd 런타임 사용)

1~6번까지 마스터, 워커 동일 설치

### 1. 스왑 비활성화

- 쿠버네티스는 컨테이너의 메모리 사용량을 정확히 예측하고 제어해야 함
- 스왑을 사용하면 성능 예측이 어렵고 컨테이너 간 격리성이 떨어지기 때문에 비활성화 필요

```bash
# 모든 스왑 공간을 즉시 비활성화
sudo swapoff -a

# /etc/fstab 파일에서 스왑 관련 라인을 주석 처리하여 재부팅 후에도 스왑이 비활성화 상태 유지
sudo sed -i '/ swap / s/^\(.*\)$/#\1/g' /etc/fstab
```

### 2. 네트워크 모듈 설정

- overlay: 컨테이너 네트워크 구성에 필요
- br_netfilter: 브리지 네트워크를 통한 패킷 필터링 지원

```bash
# 필요한 모듈 설정 파일 생성
cat <<EOF | sudo tee /etc/modules-load.d/k8s.conf
overlay
br_netfilter
EOF

# 모듈 로드
sudo modprobe overlay
sudo modprobe br_netfilter
```

### 3. 네트워크 파라미터 설정

기본적으로 Linux 커널은 인터페이스 간에 IPv4 패킷을 라우팅하는 것을 허용하지 않음. 보통은 k8s 클러스터 네트워킹이 이 설정을 자동으로 변경하지만 직접 설정해야 할수도 있음.

- IPv4 패킷 전달 활성화 → 클러스터 내 통신 가능

```bash
# 컨테이너 간 네트워크 통신을 위한 브리지 네트워크 설정
****cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-iptables  = 1
net.bridge.bridge-nf-call-ip6tables = 1
net.ipv4.ip_forward                 = 1
EOF

sudo sysctl --system
```

### 4. 컨테이너 런타임 설치

[컨테이너 런타임](https://kubernetes.io/ko/docs/setup/production-environment/container-runtimes/)

- 파드가 노드에서 실행될 수 있도록 각 노드에 설치 필요
- 우리 프로젝트는 containerd를 사용함
  - docker 컨테이너보다 가볍다는 장점이 있음

```bash
# containerd 재설치
sudo apt-get update
sudo apt-get install -y containerd.io

# containerd 설정
sudo mkdir -p /etc/containerd
containerd config default | sudo tee /etc/containerd/config.toml
sudo sed -i 's/SystemdCgroup = false/SystemdCgroup = true/' /etc/containerd/config.toml
sudo systemctl restart containerd
```

### 5. k8s 리포지토리 설정 및 설치

```bash
# 리포지토리 추가, 버전 확인 필
sudo apt-get update
sudo apt-get install -y apt-transport-https ca-certificates curl
curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.29/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg
echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.29/deb/ /' | sudo tee /etc/apt/sources.list.d/kubernetes.list

# 패키지 설치
sudo apt-get update
sudo apt-get install -y kubelet=1.29.7-1.1 kubeadm=1.29.7-1.1 kubectl=1.29.7-1.1.  # 버전 명시 -> 노드간 버전 통일 필수
sudo apt-mark hold kubelet kubeadm kubectl   # 맘대로 버전 업그레이드 안되게 홀드
```

### 6. 설치 상태 확인

```bash
# 1. containerd 상태 확인
sudo systemctl status containerd

# 2. kubelet 상태 확인
sudo systemctl status kubelet

# 3. 설치된 k8s 도구들의 버전 확인
kubectl version --client
kubeadm version
kubelet --version

# 4. crictl로 컨테이너 런타임 연결 상태 확인
sudo crictl info
```

예상되는 결과:

1. containerd가 active (running) 상태여야 합니다
2. kubelet은 아직 클러스터가 구성되지 않아서 활성화되지 않은 상태일 수 있습니다 (이는 정상)
3. kubectl, kubeadm, kubelet이 모두 동일한 버전으로 설치되어 있어야 합니다
4. crictl info가 containerd와 정상적으로 통신할 수 있어야 합니다

### 7. 마스터 노드 초기화 (6443, 10250포트 열려있어야함)

```bash
# 더 자세한 로그를 보려면 -v 플래그를 사용

# cni를 flannel 쓸거면
sudo kubeadm init --pod-network-cidr=10.244.0.0/16 --control-plane-endpoint="k11a107.p.ssafy.io" -v=5

# cni를 cilium으로 쓸거면
sudo kubeadm init --pod-network-cidr=10.1.1.0/24 --control-plane-endpoint="k11a107.p.ssafy.io" -v=5

# Calico 사용시
sudo kubeadm init --pod-network-cidr=192.168.0.0/16 --control-plane-endpoint="k11a107.p.ssafy.io" -v=5

# 초기화 성공 후 설정
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config

#CNI 플러그인 설치
# Flannel을 사용할 경우
kubectl apply -f https://raw.githubusercontent.com/flannel-io/flannel/master/Documentation/kube-flannel.yml

# Calico를 사용할 경우
kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml
```

→ DNS 조회 실패(도메인 해석 실패)로 API 서버 연결 문제 발생, 인증서 관련 문제가 발생한다면

1. 호스트 파일에 도메인 추가

```bash
sudo sh -c "echo '$(hostname -i) k11a107.p.ssafy.io' >> /etc/hosts"
```

1. 워커 노드에 CNI 바이너리 설치 필요

```bash
# 필요한 디렉토리들을 생성
sudo mkdir -p /etc/kubernetes/manifests

# CNI 바이너리가 제대로 설치되어 있는지 확인
ls -la /opt/cni/bin/

# CNI 바이너리가 없다면 설치
sudo mkdir -p /opt/cni/bin
cd /opt/cni/bin
sudo wget https://github.com/containernetworking/plugins/releases/download/v1.3.0/cni-plugins-linux-amd64-v1.3.0.tgz
sudo tar -xzvf cni-plugins-linux-amd64-v1.3.0.tgz

# 기존 CNI 설정 제거
sudo rm -rf /etc/cni/net.d/*

# kubelet 재시작
sudo systemctl restart kubelet

# 마스터 노드에서 Flannel을 재설치
kubectl delete -f https://raw.githubusercontent.com/flannel-io/flannel/master/Documentation/kube-flannel.yml
kubectl apply -f https://raw.githubusercontent.com/flannel-io/flannel/master/Documentation/kube-flannel.yml
```

### 8. 워커 노드 Join - 우리 서버는 VPN을 사용함으로 join전에 9번부터 실행

- 마스터 노드에서 kubedam init 명령어 실행시 가장 마지막에 나오는 `kubeadm join ~` 명령어가 join 명령어임
- 토큰을 잃어버렸다면, 마스터 노드에서 다음 명령어로 새 토큰 생성 가능

```bash
# 마스터 노드에서
kubeadm token create --print-join-command

# 결과 내용을 워커 노드에서
sudo kubeadm join 어쩌구저쩌구 실행
```

‼️ g4 서버 gpu관련 설정 방법 추가 필요

그냥 nvidia driver plugin만 설치했을때 cuda 뭐시기를 설치안한 상태여서 계속 데몬셋이 안떴음

도형오빠가 설치해주고 나서 정상이 됐고, flannel 인증서 경로 불일치로 연결이 안됐음

### 9. VPN 설치 및 설정 (native)

마스터 노드와 워커 노드가 서로 다른 aws 계정에 속해있어 서브넷이 다른 것이 문제.

쿠버네티스에서는 노드간 통신을 private ip를 통해서 하는데, 서브넷이 다르면 private ip를 인식할 수가 없음

따라서 vpn 설정을 통해 우회 통신을 하도록 함

- **WireGuard 선택 이유**:
  - 빠른 성능 (OpenVPN보다 우수)
  - 설정이 간단함
  - 커널레벨 지원으로 안정성이 높음
  - 낮은 오버헤드
- **Native 설치 추천 이유** (이 경우에는 Native 설치가 더 적합):
  - 쿠버네티스 네트워크와 직접 통합 필요
  - 네트워크 성능이 중요
  - 시스템 수준의 네트워크 설정 필요
  - 컨테이너 네트워크와의 간섭 최소화

```bash
# WireGuard 설치
sudo apt update
sudo apt install wireguard
```

- 마스터 노드

```bash
# 키 생성 (마스터 노드)
wg genkey | sudo tee /etc/wireguard/private.key
sudo chmod go= /etc/wireguard/private.key
sudo cat /etc/wireguard/private.key | wg pubkey | sudo tee /etc/wireguard/public.key

# WireGuard 설정 (마스터 노드)
sudo nano /etc/wireguard/wg0.conf

[Interface]
Address = 10.10.0.1/24  # VPN 네트워크 대역
PrivateKey = <마스터노드_프라이빗키>
ListenPort = 51820

[Peer]
PublicKey = <워커노드_퍼블릭키>
AllowedIPs = 10.10.0.2/32  # 워커노드의 VPN IP
```

- 워커 노드

```bash
# 키 생성 (워커 노드)
wg genkey | sudo tee /etc/wireguard/private.key
sudo chmod go= /etc/wireguard/private.key
sudo cat /etc/wireguard/private.key | wg pubkey | sudo tee /etc/wireguard/public.key

# WireGuard 설정 (워커 노드)
sudo nano /etc/wireguard/wg0.conf

[Interface]
Address = 10.10.0.2/24  # VPN 네트워크 대역
PrivateKey = <워커노드_프라이빗키>

[Peer]
PublicKey = <마스터노드_퍼블릭키>
AllowedIPs = 10.10.0.0/24
Endpoint = <마스터노드_퍼블릭IP>:51820
PersistentKeepalive = 25
```

- 양쪽 모두

```bash
# 양쪽 노드 모두에서 실행
sudo systemctl enable wg-quick@wg0
sudo systemctl start wg-quick@wg0

# 상태 확인
sudo wg show

# IP 포워딩 활성화 (양쪽 노드)
echo "net.ipv4.ip_forward=1" | sudo tee -a /etc/sysctl.conf
sudo sysctl -p

# 방화벽 설정 (필요한 경우)
sudo ufw allow 51820/udp

# 연결 테스트
ping 10.10.0.1  # 워커노드에서
ping 10.10.0.2  # 마스터노드에서
```

- 마스터 노드에서 kubeadm 설정을 업데이트 하여 VPN IP 추가 필요

```bash
# 마스터 노드에서
sudo vim /etc/kubernetes/manifests/kube-apiserver.yaml
```

```yaml
# certSANs 섹션에 VPN IP를 추가
apiVersion: v1
kind: Pod
metadata:
  name: kube-apiserver
  namespace: kube-system
spec:
  containers:
    - command:
        - kube-apiserver
        - --cert-dir=/var/lib/kubernetes/pki.
        # 다른 설정들...
        - --service-account-key-file=/etc/kubernetes/pki/sa.pub
        - --tls-cert-file=/etc/kubernetes/pki/apiserver.crt
        - --tls-private-key-file=/etc/kubernetes/pki/apiserver.key
        - --service-cluster-ip-range=10.96.0.0/12
```

```bash
# 마스터 노드에서 API 서버 인증서를 재생성
sudo kubeadm init phase certs apiserver --apiserver-advertise-address=10.10.0.1 --apiserver-cert-extra-sans=10.10.0.1,172.26.13.245,k11a107.p.ssafy.io

# 또는 아예 init 처음부터 한번에 설정할 때
sudo kubeadm init \
  --pod-network-cidr=10.244.0.0/16 \
  --control-plane-endpoint="k11a107.p.ssafy.io" \
  --apiserver-cert-extra-sans=10.10.0.1,k11a107.p.ssafy.io \
  -v=5

# 마스터 노드에서
sudo crictl rm -f $(sudo crictl ps | grep kube-apiserver | awk '{print $1}')
```

```bash
# 워커노드 조인 시
kubeadm join <마스터노드_VPN_IP>:6443 --token <토큰> \
    --discovery-token-ca-cert-hash <해시값> \
    --apiserver-advertise-address=10.10.0.2 \
	  --node-name=ip-172-31-37-13
```

주의사항:

1. 보안 그룹/방화벽에서 UDP 51820 포트 개방 필요
2. 서브넷 라우팅 테이블 확인
3. MTU 설정 확인 (필요한 경우 조정)
4. 노드 간 시간 동기화 확인

### 10. 각종 config 수정

- Flannel ConfigMap 수정:

```bash

kubectl edit configmap -n kube-flannel kube-flannel-cfg
```

net-conf.json 부분을 다음과 같이 수정:

```json
{
  "Network": "10.244.0.0/16",
  "EnableNFTables": false,
  "Backend": {
    "Type": "vxlan",
    "DirectRouting": true
  }
}
```

- Flannel DaemonSet 수정하여 wg0 인터페이스 사용:

```bash
kubectl edit daemonset -n kube-flannel kube-flannel-ds
```

containers 아래 args에 다음 옵션 추가:

```yaml
- --iface=wg0
- --ip-masq
- --kube-subnet-mgr
- --kubeconfig-file=/etc/kubernetes/flannel/kubeconfig # 이미 있는 내용을 수정해야할수도
```

- 워커노드의 kubelet 설정 수정:

```bash
# 워커노드에서 실행
sudo vi /var/lib/kubelet/kubeadm-flags.env
```

다음과 같이 수정:

```
KUBELET_KUBEADM_ARGS="--container-runtime-endpoint=unix:///var/run/containerd/containerd.sock --pod-infra-container-image=registry.k8s.io/pause:3.9 --node-ip=10.10.0.2"
```

- kubelet 재시작:

```bash
# 워커노드에서 실행
sudo systemctl restart kubelet
```

- 워커노드의 hostname과 IP 매핑 추가

```bash
# 워커노드에서
sudo sh -c 'echo "10.10.0.1 ip-172-26-13-245" >> /etc/hosts'
# 마스터노드에서
sudo sh -c 'echo "10.10.0.2 ip-172-31-37-13" >> /etc/hosts'
```

‼️Flannel이 kubelet 인증서를 찾지 못하는 오류 발생시, 인증서를 찾을 수 있도록 볼륨 마운트 추가 필요

```bash
# Flannel DaemonSet 수정하려면
kubectl edit daemonset -n kube-flannel kube-flannel-ds
```

- spec.template.spec에 다음과 같이 볼륨과 볼륨마운트를 추가/수정

```yaml
spec:
  template:
    spec:
      containers:
        - name: kube-flannel
          args:
            - --iface=wg0
            - --ip-masq
            - --kube-subnet-mgr
            - --kubeconfig-file=/etc/kubernetes/flannel/kubeconfig
          volumeMounts:
            # 기존 볼륨마운트들...
            - name: kubelet-certs
              mountPath: /var/lib/kubelet/pki
              readOnly: true
      volumes:
        # 기존 볼륨들...
        - name: kubelet-certs
          hostPath:
            path: /var/lib/kubelet/pki
            type: Directory
```

```yaml
# Flannel 파드들 재시작
kubectl delete pods -n kube-flannel --all
```

### 11. CuDNN 설치

11번 부터 GPU 서버 구성

CuDNN은 딥러닝 관련해서 GPU 구동을 도와주는 패키지다.

[설치하고자 하는 버전의 링크를 찾아서 들어가자](https://developer.nvidia.com/cudnn-downloads)

```bash
wget https://developer.download.nvidia.com/compute/cudnn/9.5.1/local_installers/cudnn-local-repo-ubuntu2004-9.5.1_1.0-1_amd64.deb
sudo dpkg -i cudnn-local-repo-ubuntu2004-9.5.1_1.0-1_amd64.deb
sudo cp /var/cudnn-local-repo-ubuntu2004-9.5.1/cudnn-*-keyring.gpg /usr/share/keyrings/
sudo apt-get update
sudo apt-get -y install cudnn
```

### 12. Nvidia GPU Drivers

서버가 GPU를 인식할 수 있도록 한다.

[gpu 사양에 맞는 것을 설치한다.](https://www.nvidia.com/en-us/drivers/)

```bash
sudo apt install nvidia-driver-버전
```

### 13. Nvidia Container Toolkit

[링크를 참고해 잘 설치해보자.](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html)

### 14. Nvidia Device Plugin

```bash
kubectl apply -f nvidia-device-plugin.yaml
```

### 15. Nvidia CUDA Toolkit

ver 11.8

deb(local), deb(network), runfile 방식이 있는데, runfile, deb(local)을 추천한다. 네트워크는 에러가 많다.

```bash
wget https://developer.download.nvidia.com/compute/cuda/11.8.0/local_installers/cuda_11.8.0_520.61.05_linux.run
sudo sh cuda_11.8.0_520.61.05_linux.run
```

## 쿠버네티스 리소스 파일

### actuator-secret

```yaml
apiVersion: v1
kind: Secret
metadata:
  name: actuator-credentials
  namespace: scv
type: Opaque
data:
  ACTUATOR_PASSWORD: YTEwN3Njdn4hQA== # a107scv~!@
```

### aes-secret

```yaml
apiVersion: v1
kind: Secret
metadata:
  name: aes-secret
  namespace: scv
type: Opaque
data:
  key: c2N2aXNiZXN0YWlhcHB+IQ== # scvisbestaiapp~!
```

### back

```yaml
# back.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: backend
  namespace: scv
spec:
  replicas: 1
  selector:
    matchLabels:
      app: backend
  template:
    metadata:
      labels:
        app: backend
    spec:
      nodeSelector:
        node-type: basic
      volumes:
        - name: tz-config
          hostPath:
            path: /etc/localtime
      containers:
        - name: backend
          image: a107scv/scv-back:latest
          imagePullPolicy: Always
          volumeMounts:
            - mountPath: /etc/localtime
              name: tz-config
              readOnly: true
          ports:
            - containerPort: 8080
          resources:
            requests:
              memory: "512Mi"
              cpu: "250m"
            limits:
              memory: "1Gi"
              cpu: "500m"
          readinessProbe:
            httpGet:
              path: /actuator/health/readiness
              port: 8080
              httpHeaders:
                - name: Authorization
                  value: "Basic YWN0dWF0b3I6eW91ci1wYXNzd29yZA=="
            initialDelaySeconds: 30
            periodSeconds: 10
          livenessProbe:
            httpGet:
              path: /actuator/health/liveness
              port: 8080
              httpHeaders:
                - name: Authorization
                  value: "Basic YWN0dWF0b3I6YTEwN3Njdn4hQA=="
            initialDelaySeconds: 45
            periodSeconds: 15
          env:
            - name: JAVA_TOOL_OPTIONS
              value: "-Duser.timezone=Asia/Seoul"
            - name: ACTUATOR_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: actuator-credentials
                  key: ACTUATOR_PASSWORD
            - name: DB_URL
              value: jdbc:mysql://mysql.scv.svc.cluster.local:3306/scv?useSSL=false&serverTimezone=Asia/Seoul&characterEncoding=UTF-8&allowPublicKeyRetrieval=true
            - name: DB_USERNAME
              valueFrom:
                secretKeyRef:
                  name: mysql-secret
                  key: user
            - name: DB_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: mysql-secret
                  key: password
            - name: JWT_ACCESS_NAME
              valueFrom:
                secretKeyRef:
                  name: jwt-secret
                  key: access-name
            - name: JWT_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: jwt-secret
                  key: access-key
            - name: JWT_ACCESS_EXPIRATION
              value: "3600"
            - name: JWT_REFRESH_NAME
              valueFrom:
                secretKeyRef:
                  name: jwt-secret
                  key: refresh-name
            - name: JWT_REFRESH_KEY
              valueFrom:
                secretKeyRef:
                  name: jwt-secret
                  key: refresh-key
            - name: JWT_REFRESH_EXPIRATION
              value: "1209600"
            - name: DOMAIN
              value: "https://k11a107.p.ssafy.io"

            - name: OAUTH_CLIENT_ID
              valueFrom:
                secretKeyRef:
                  name: github-secret
                  key: client-id
            - name: OAUTH_CLIENT_SECRET
              valueFrom:
                secretKeyRef:
                  name: github-secret
                  key: client-secret
            - name: OAUTH_REDIRECT_URI
              value: "https://k11a107.p.ssafy.io/api/login/oauth2/code/github"

            # Redis Access Token 관련 환경변수
            - name: REDIS_ACCESS_MASTER_HOST
              value: "redis-access-master.scv.svc.cluster.local"
            - name: REDIS_ACCESS_MASTER_PORT
              value: "6379"
            - name: REDIS_ACCESS_MASTER_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: redis-secret
                  key: password
            - name: REDIS_ACCESS_SLAVE1_HOST
              value: "redis-access-slave1.scv.svc.cluster.local"
            - name: REDIS_ACCESS_SLAVE1_PORT
              value: "6379"
            - name: REDIS_ACCESS_SLAVE1_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: redis-secret
                  key: password
            - name: REDIS_ACCESS_SLAVE2_HOST
              value: "redis-access-slave2.scv.svc.cluster.local"
            - name: REDIS_ACCESS_SLAVE2_PORT
              value: "6379"
            - name: REDIS_ACCESS_SLAVE2_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: redis-secret
                  key: password
            - name: REDIS_ACCESS_SLAVE3_HOST
              value: "redis-access-slave3.scv.svc.cluster.local"
            - name: REDIS_ACCESS_SLAVE3_PORT
              value: "6379"
            - name: REDIS_ACCESS_SLAVE3_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: redis-secret
                  key: password
            # Redis Refresh Token 관련 환경변수
            - name: REDIS_REFRESH_MASTER_HOST
              value: "redis-refresh-master.scv.svc.cluster.local"
            - name: REDIS_REFRESH_MASTER_PORT
              value: "6379"
            - name: REDIS_REFRESH_MASTER_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: redis-secret
                  key: password
            # Redis Oauth Token
            - name: REDIS_OAUTH_MASTER_HOST
              value: "redis-oauth-master.scv.svc.cluster.local"
            - name: REDIS_OAUTH_MASTER_PORT
              value: "6379"
            - name: REDIS_OAUTH_MASTER_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: redis-secret
                  key: password

            - name: FAST_MODEL_TRAIN_HOST_NAME
              value: fast-train-service.scv.svc.cluster.local
            - name: FAST_MODEL_TRAIN_PORT
              value: "8003"
            - name: FAST_MODEL_TEST_HOST_NAME
              value: fast-test-service.scv.svc.cluster.local
            - name: FAST_MODEL_TEST_PORT
              value: "8002"

            - name: AES_SECRET_KEY
              valueFrom:
                secretKeyRef:
                  name: aes-secret
                  key: key

---
apiVersion: v1
kind: Service
metadata:
  name: backend
  namespace: scv
spec:
  selector:
    app: backend
  ports:
    - name: http
      port: 8080
      targetPort: 8080
  type: ClusterIP
```

### github-secret

```yaml
apiVersion: v1
kind: Secret
metadata:
  name: github-secret
  namespace: scv
type: Opaque
data:
  client-id: T3YyM2xpak1DTm0wa0FSM2lnazY=
  client-secret: ZmQxYzM1NDc0OTNmYzkwMTQ5YjY2NDMxYWQ2MjQ4ZTVkYzQwN2Y5Yw==
```

### jwt-secret

```yaml
apiVersion: v1
kind: Secret
metadata:
  name: jwt-secret
  namespace: scv
type: Opaque
data:
  access-name: QUNU
  access-key: c2N2c2N2c2N2c2N2c2N2c2N2c2N2c2N2c2N2c2N2c2N2c2N2c2N2c2N2c2N2c2N2c2N2c2N2c2N2c2N2MQ==
  refresh-name: UkZU
  refresh-key: c2N2c2N2c2N2c2N2c2N2c2N2c2N2c2N2c2N2c2N2c2N2c2N2c2N2c2N2c2N2c2N2c2N2c2N2c2N2c2N2Mg==
```

### fast-redis

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: fast-redis
  namespace: scv
  labels:
    app: fast-redis
spec:
  replicas: 1
  selector:
    matchLabels:
      app: fast-redis
  template:
    metadata:
      labels:
        app: fast-redis
    spec:
      nodeSelector:
        node-type: gpu # 'gpu' 레이블이 있는 노드에서만 실행되도록 지정
      containers:
        - name: redis
          image: redis
          command: ["redis-server", "--port", "6380"]
          ports:
            - containerPort: 6380
          resources:
            requests:
              memory: "512Mi"
              cpu: "250m"
            limits:
              memory: "1Gi"
              cpu: "500m"
          volumeMounts:
            - name: tz-config
              mountPath: /etc/localtime
              readOnly: true
      volumes:
        - name: tz-config
          hostPath:
            path: /etc/localtime
            type: File
```

### fast-search

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: fast-model-search
  namespace: scv
spec:
  replicas: 1
  selector:
    matchLabels:
      app: scv-model-search
  template:
    metadata:
      labels:
        app: scv-model-search
    spec:
      nodeSelector:
        node-type: gpu # node-type=gpu 레이블이 있는 노드에서만 실행되도록 설정
      containers:
        - name: scv-model-search
          image: a107scv/scv-model-search
          env:
            - name: REDIS_HOST_NAME
              value: "localhost"
            - name: REDIS_PORT
              value: "6379"
            - name: DB_NAME
              value: "scv_database"
            - name: COLLECTION_NAME
              value: "cka_collection"
            - name: API_KEY
              valueFrom:
                secretKeyRef:
                  name: fast-search-secrets
                  key: API_KEY
          ports:
            - containerPort: 8001 # 컨테이너가 사용할 포트
          resources:
            requests:
              memory: "1Gi" # 메모리 요청
              cpu: "1" # CPU 요청
            limits:
              memory: "2Gi" # 메모리 제한
              cpu: "2" # CPU 제한
          volumeMounts:
            - name: milvus-data
              mountPath: /data
            - name: tz-config
              mountPath: /etc/localtime
              readOnly: true
        - name: redis-service
          image: redis
          command:
            [
              "redis-server",
              "--port",
              "6379",
              "--bind",
              "0.0.0.0",
              "--protected-mode",
              "no",
            ]
          ports:
            - containerPort: 6379
      restartPolicy: Always
      volumes:
        - name: milvus-data
          hostPath:
            path: /mnt/data/milvus
            type: DirectoryOrCreate
        - name: tz-config
          hostPath:
            path: /etc/localtime
            type: File
```

### fast-test

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: fast-model-test
  namespace: scv
spec:
  replicas: 1
  selector:
    matchLabels:
      app: scv-model-test
  template:
    metadata:
      labels:
        app: scv-model-test
    spec:
      nodeSelector:
        node-type: gpu # node-type=gpu 레이블이 있는 노드에서만 실행되도록 설정
      containers:
        - name: scv-model-test
          image: a107scv/scv-model-test
          env:
            - name: MINIO_HOST_NAME
              value: "fast-minio-service.scv.svc.cluster.local"
            - name: MINIO_PORT
              value: "9002"
            - name: MINIO_MODEL_BUCKET
              value: "scv-model-bucket"
            - name: MINIO_DATASET_BUCKET
              value: "scv-dataset-bucket"
            - name: FAST_MATCH_HOST_NAME
              value: "fast-search-service.scv.svc.cluster.local"
            - name: FAST_MATCH_PORT
              value: "8001"
            - name: MINIO_ROOT_USER
              valueFrom:
                secretKeyRef:
                  name: minio-credentials
                  key: MINIO_ROOT_USER
            - name: MINIO_ROOT_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: minio-credentials
                  key: MINIO_ROOT_PASSWORD
            - name: MINIO_USER_NAME
              valueFrom:
                secretKeyRef:
                  name: minio-credentials
                  key: MINIO_ROOT_USER
            - name: MINIO_USER_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: minio-credentials
                  key: MINIO_ROOT_PASSWORD
          ports:
            - containerPort: 8002 # 컨테이너가 사용할 포트
          resources:
            requests:
              memory: "1Gi" # 메모리 요청
              cpu: "500m" # CPU 요청
            limits:
              memory: "2Gi" # 메모리 제한
              cpu: "2" # CPU 제한
          volumeMounts:
            - name: dataset
              mountPath: /data
            - name: tz-config
              mountPath: /etc/localtime
              readOnly: true
      volumes:
        - name: dataset
          hostPath:
            path: /mnt/data/datasets
            type: DirectoryOrCreate
        - name: tz-config
          hostPath:
            path: /etc/localtime
            type: File
      restartPolicy: Always
```

### fast-train

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: fast-model-train
  namespace: scv
spec:
  replicas: 1
  selector:
    matchLabels:
      app: scv-model-train
  template:
    metadata:
      labels:
        app: scv-model-train
    spec:
      nodeSelector:
        node-type: gpu # node-type=gpu 레이블이 있는 노드에서만 실행되도록 설정
      containers:
        - name: scv-model-train
          image: a107scv/scv-model-train
          env:
            - name: MINIO_HOST_NAME
              value: "fast-minio-service.scv.svc.cluster.local"
            - name: MINIO_API_PORT
              value: "9002"
            - name: MINIO_MODEL_BUCKET
              value: "scv-model-bucket"
            - name: MINIO_USER_NAME
              valueFrom:
                secretKeyRef:
                  name: minio-credentials
                  key: MINIO_ROOT_USER
            - name: MINIO_USER_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: minio-credentials
                  key: MINIO_ROOT_PASSWORD
          ports:
            - containerPort: 8003 # 컨테이너가 사용할 포트
          resources:
            requests:
              memory: "1Gi" # 메모리 요청
              cpu: "500m" # CPU 요청
              nvidia.com/gpu: 1
            limits:
              memory: "2Gi" # 메모리 제한
              cpu: "2" # CPU 제한
              nvidia.com/gpu: 1
          volumeMounts:
            - name: tz-config
              mountPath: /etc/localtime
              readOnly: true
      volumes:
        - name: tz-config
          hostPath:
            path: /etc/localtime
            type: File
      restartPolicy: Always
```

### minio

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: fast-minio
  namespace: scv
spec:
  replicas: 1
  selector:
    matchLabels:
      app: fast-minio
  template:
    metadata:
      labels:
        app: fast-minio
    spec:
      nodeSelector:
        node-type: gpu # gpu 레이블이 있는 노드에서만 실행
      containers:
        - name: minio
          image: minio/minio
          ports:
            - containerPort: 9002
            - containerPort: 9003
          env:
            - name: MINIO_ROOT_USER
              valueFrom:
                secretKeyRef:
                  name: minio-credentials
                  key: MINIO_ROOT_USER
            - name: MINIO_ROOT_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: minio-credentials
                  key: MINIO_ROOT_PASSWORD
            - name: MINIO_VOLUMES
              value: /data
          volumeMounts:
            - name: minio-data
              mountPath: /data
            - name: minio-config
              mountPath: /etc
            - name: tz-config
              mountPath: /etc/localtime
              readOnly: true
          command:
            [
              "minio",
              "server",
              "--address",
              ":9002",
              "--console-address",
              ":9003",
            ]
      volumes:
        - name: minio-data
          hostPath:
            path: /mnt/data/minio
            type: DirectoryOrCreate
        - name: minio-config
          hostPath:
            path: /mnt/data/minio/config
            type: DirectoryOrCreate
        - name: tz-config
          hostPath:
            path: /etc/localtime
            type: File
```

### front.yaml

```yaml
# front.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
  namespace: scv
spec:
  replicas: 1
  selector:
    matchLabels:
      app: frontend
  template:
    metadata:
      labels:
        app: frontend
    spec:
      nodeSelector:
        node-type: basic
      containers:
        - name: frontend
          image: a107scv/scv-front:latest
          imagePullPolicy: Always
          ports:
            - containerPort: 3000
          resources:
            requests:
              memory: "256Mi"
              cpu: "200m"
            limits:
              memory: "512Mi"
              cpu: "400m"
          readinessProbe:
            httpGet:
              path: /
              port: 3000
            initialDelaySeconds: 20
            periodSeconds: 10
          livenessProbe:
            httpGet:
              path: /
              port: 3000
            initialDelaySeconds: 30
            periodSeconds: 15
          volumeMounts:
            - mountPath: /etc/localtime
              name: tz-config
              readOnly: true
      volumes:
        - name: tz-config
          hostPath:
            path: /etc/localtime

---
apiVersion: v1
kind: Service
metadata:
  name: frontend
  namespace: scv
spec:
  type: ClusterIP
  selector:
    app: frontend
  ports:
    - port: 3000
      targetPort: 3000
```

### mysql

```yaml
# mysql.yaml
apiVersion: v1
kind: Service
metadata:
  name: mysql
  namespace: scv
spec:
  ports:
    - port: 3306
      targetPort: 3306
      nodePort: 30100
  selector:
    app: mysql
  type: NodePort
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mysql
  namespace: scv
spec:
  replicas: 1
  selector:
    matchLabels:
      app: mysql
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        app: mysql
    spec:
      nodeSelector:
        node-type: basic
      containers:
        - name: mysql
          image: mysql:8.0.39
          env:
            - name: MYSQL_ROOT_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: mysql-secret
                  key: root-password
            - name: MYSQL_DATABASE
              value: scv
            - name: MYSQL_USER
              valueFrom:
                secretKeyRef:
                  name: mysql-secret
                  key: user
            - name: MYSQL_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: mysql-secret
                  key: password
          ports:
            - containerPort: 3306
              name: mysql
          volumeMounts:
            - name: mysql-persistent-storage
              mountPath: /var/lib/mysql
            - mountPath: /etc/localtime
              name: tz-config
              readOnly: true
      volumes:
        - name: mysql-persistent-storage
          hostPath:
            path: /var/lib/mysql-k8s
            type: DirectoryOrCreate
        - name: tz-config
          hostPath:
            path: /etc/localtime
```

### sql-secret

```yaml
# sql-secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: mysql-secret
  namespace: scv
type: Opaque
data:
  root-password: YTEwN3Njdn4hQA==
  user: YTEwN3Njdg==
  password: YTEwN3Njdn4hQA==
```

### ingress-controlloer-service

```yaml
apiVersion: v1
kind: Service
metadata:
  name: ingress-nginx-controller
  namespace: ingress-nginx
spec:
  type: NodePort # 다시 NodePort로 변경
  selector:
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/component: controller
  ports:
    - name: http
      port: 80
      targetPort: 80
      nodePort: 30080 # 명시적으로 포트 지정
```

### nginx-config

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: ingress-nginx-controller
  namespace: ingress-nginx
data:
  allow-snippet-annotations: "true"
  tcp-services-configmap: "ingress-nginx/tcp-services"
  allow-backend-server-header: "true"
  enable-real-ip: "true"
  proxy-stream-timeout: "600s"
  proxy-stream-responses: "1"
```

### tcp-service

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: tcp-services
  namespace: ingress-nginx
data:
  "3306": "scv/mysql:3306"
```

### scv-ingress

```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: scv-ingress
  namespace: scv
#  annotations:
#    nginx.ingress.kubernetes.io/rewrite-target: /$2
#    nginx.ingress.kubernetes.io/use-regex: "true"  # 정규식 사용 설정 추가
spec:
  ingressClassName: nginx
  rules:
    - host: k11a107.p.ssafy.io
      http:
        paths:
          #      - path: /api(/|$)(.*)
          #        pathType: ImplementationSpecific  # Prefix 대신
          - path: /api
            pathType: Prefix
            backend:
              service:
                name: backend
                port:
                  number: 8080
          - path: /oauth2
            pathType: Prefix
            backend:
              service:
                name: backend
                port:
                  number: 8080
          - path: /
            pathType: Prefix
            backend:
              service:
                name: frontend
                port:
                  number: 3000
          - path: /fast/v1/model/match
            pathType: Prefix
            backend:
              service:
                name: fast-search-service
                port:
                  number: 8001
          - path: /fast/v1/model/test
            pathType: Prefix
            backend:
              service:
                name: fast-test-service
                port:
                  number: 8002
          - path: /fast/v1/models
            pathType: Prefix
            backend:
              service:
                name: fast-train-service
                port:
                  number: 8003
```

### redis-master

```yaml
apiVersion: v1
kind: Service
metadata:
  name: redis-access-master
  namespace: scv
spec:
  selector:
    app: redis-access-master
  ports:
    - name: redis
      port: 6379
      targetPort: 6379
  type: ClusterIP
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-access-master
  namespace: scv
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis-access-master
  template:
    metadata:
      labels:
        app: redis-access-master
    spec:
      nodeSelector:
        node-type: basic
      containers:
        - name: redis
          image: redis:7.4.1
          ports:
            - containerPort: 6379
          args:
            - "redis-server"
            - "--port"
            - "6379"
            - "--bind"
            - "0.0.0.0"
            - "--protected-mode"
            - "no"
            - "--requirepass"
            - "$(REDIS_PASSWORD)"
          env:
            - name: REDIS_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: redis-secret
                  key: password
          resources:
            requests:
              memory: "256Mi"
              cpu: "100m"
            limits:
              memory: "512Mi"
              cpu: "200m"
          volumeMounts:
            - name: tz-config
              mountPath: /etc/localtime
              readOnly: true
      volumes:
        - name: tz-config
          hostPath:
            path: /etc/localtime
            type: File
---
# Redis Access Slave 1
apiVersion: v1
kind: Service
metadata:
  name: redis-access-slave1
  namespace: scv
spec:
  selector:
    app: redis-access-slave1
  ports:
    - name: redis
      port: 6379
      targetPort: 6379
  type: ClusterIP
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-access-slave1
  namespace: scv
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis-access-slave1
  template:
    metadata:
      labels:
        app: redis-access-slave1
    spec:
      nodeSelector:
        node-type: basic
      containers:
        - name: redis
          image: redis:7.4.1
          ports:
            - containerPort: 6379
          args:
            - "redis-server"
            - "--port"
            - "6379"
            - "--bind"
            - "0.0.0.0"
            - "--protected-mode"
            - "no"
            - "--requirepass"
            - "$(REDIS_PASSWORD)"
          env:
            - name: REDIS_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: redis-secret
                  key: password
          resources:
            requests:
              memory: "256Mi"
              cpu: "100m"
            limits:
              memory: "512Mi"
              cpu: "200m"
          volumeMounts:
            - name: tz-config
              mountPath: /etc/localtime
              readOnly: true
      volumes:
        - name: tz-config
          hostPath:
            path: /etc/localtime
            type: File
---
# Redis Access Slave 2
apiVersion: v1
kind: Service
metadata:
  name: redis-access-slave2
  namespace: scv
spec:
  selector:
    app: redis-access-slave2
  ports:
    - name: redis
      port: 6379
      targetPort: 6379
  type: ClusterIP
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-access-slave2
  namespace: scv
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis-access-slave2
  template:
    metadata:
      labels:
        app: redis-access-slave2
    spec:
      nodeSelector:
        node-type: basic
      containers:
        - name: redis
          image: redis:7.4.1
          ports:
            - containerPort: 6379
          args:
            - "redis-server"
            - "--port"
            - "6379"
            - "--bind"
            - "0.0.0.0"
            - "--protected-mode"
            - "no"
            - "--requirepass"
            - "$(REDIS_PASSWORD)"
          env:
            - name: REDIS_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: redis-secret
                  key: password
          resources:
            requests:
              memory: "256Mi"
              cpu: "100m"
            limits:
              memory: "512Mi"
              cpu: "200m"
          volumeMounts:
            - name: tz-config
              mountPath: /etc/localtime
              readOnly: true
      volumes:
        - name: tz-config
          hostPath:
            path: /etc/localtime
            type: File
---
# Redis Access Slave 3
apiVersion: v1
kind: Service
metadata:
  name: redis-access-slave3
  namespace: scv
spec:
  selector:
    app: redis-access-slave3
  ports:
    - name: redis
      port: 6379
      targetPort: 6379
  type: ClusterIP
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-access-slave3
  namespace: scv
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis-access-slave3
  template:
    metadata:
      labels:
        app: redis-access-slave3
    spec:
      nodeSelector:
        node-type: basic
      containers:
        - name: redis
          image: redis:7.4.1
          ports:
            - containerPort: 6379
          args:
            - "redis-server"
            - "--port"
            - "6379"
            - "--bind"
            - "0.0.0.0"
            - "--protected-mode"
            - "no"
            - "--requirepass"
            - "$(REDIS_PASSWORD)"
          env:
            - name: REDIS_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: redis-secret
                  key: password
          resources:
            requests:
              memory: "256Mi"
              cpu: "100m"
            limits:
              memory: "512Mi"
              cpu: "200m"
          volumeMounts:
            - name: tz-config
              mountPath: /etc/localtime
              readOnly: true
      volumes:
        - name: tz-config
          hostPath:
            path: /etc/localtime
            type: File
---
# Redis Refresh Master
apiVersion: v1
kind: Service
metadata:
  name: redis-refresh-master
  namespace: scv
spec:
  selector:
    app: redis-refresh-master
  ports:
    - name: redis
      port: 6379
      targetPort: 6379
  type: ClusterIP
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-refresh-master
  namespace: scv
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis-refresh-master
  template:
    metadata:
      labels:
        app: redis-refresh-master
    spec:
      nodeSelector:
        node-type: basic
      containers:
        - name: redis
          image: redis:7.4.1
          ports:
            - containerPort: 6379
          args:
            - "redis-server"
            - "--port"
            - "6379"
            - "--bind"
            - "0.0.0.0"
            - "--protected-mode"
            - "no"
            - "--requirepass"
            - "$(REDIS_PASSWORD)"
          env:
            - name: REDIS_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: redis-secret
                  key: password
          resources:
            requests:
              memory: "256Mi"
              cpu: "100m"
            limits:
              memory: "512Mi"
              cpu: "200m"
          volumeMounts:
            - name: tz-config
              mountPath: /etc/localtime
              readOnly: true
      volumes:
        - name: tz-config
          hostPath:
            path: /etc/localtime
            type: File
---
# Redis Oauth Master
apiVersion: v1
kind: Service
metadata:
  name: redis-oauth-master
  namespace: scv
spec:
  selector:
    app: redis-oauth-master
  ports:
    - name: redis
      port: 6379
      targetPort: 6379
  type: ClusterIP
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-oauth-master
  namespace: scv
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis-oauth-master
  template:
    metadata:
      labels:
        app: redis-oauth-master
    spec:
      nodeSelector:
        node-type: basic
      containers:
        - name: redis
          image: redis:7.4.1
          ports:
            - containerPort: 6379
          args:
            - "redis-server"
            - "--port"
            - "6379"
            - "--bind"
            - "0.0.0.0"
            - "--protected-mode"
            - "no"
            - "--requirepass"
            - "$(REDIS_PASSWORD)"
          env:
            - name: REDIS_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: redis-secret
                  key: password
          resources:
            requests:
              memory: "256Mi"
              cpu: "100m"
            limits:
              memory: "512Mi"
              cpu: "200m"
          volumeMounts:
            - name: tz-config
              mountPath: /etc/localtime
              readOnly: true
      volumes:
        - name: tz-config
          hostPath:
            path: /etc/localtime
            type: File
```

### redis-secret

```yaml
apiVersion: v1
kind: Secret
metadata:
  name: redis-secret
  namespace: scv
type: Opaque
data:
  password: YTEwN3Njdn4hQA==
```
